#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬
ç”Ÿæˆæ¨¡æ‹Ÿçš„æ–°é—»ã€å®ä½“ã€å…³ç³»æ•°æ®ç”¨äºæµ‹è¯•
"""

import asyncio
import random
import traceback
from datetime import datetime, timedelta
from sqlalchemy.ext.asyncio import AsyncSession
from app.database.manager import DatabaseManager
from app.database.models import Entity, Relation, NewsEvent
from app.database.repositories import EntityRepository, RelationRepository, NewsEventRepository
from app.store.hybrid_store_core_implement import HybridStoreCore
from app.embedding.embedding_service import EmbeddingService
from app.utils.logging_utils import get_logger

logger = get_logger(__name__)


class TestDataGenerator:
    """æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        # æš‚æ—¶ä¸åˆå§‹åŒ–HybridStoreCoreï¼Œé¿å…ä¾èµ–é—®é¢˜
        self.hybrid_store = None
        self.embedding_service = None
        
        # æµ‹è¯•æ•°æ®æ¨¡æ¿
        self.tech_companies = [
            "è‹¹æœå…¬å¸", "è°·æ­Œ", "å¾®è½¯", "äºšé©¬é€Š", "è…¾è®¯", "é˜¿é‡Œå·´å·´", "ç™¾åº¦", "å­—èŠ‚è·³åŠ¨",
            "åä¸º", "å°ç±³", "ç‰¹æ–¯æ‹‰", "è‹±ä¼Ÿè¾¾", "è‹±ç‰¹å°”", "AMD", "é«˜é€š", "ä¸‰æ˜Ÿ"
        ]
        
        self.ai_concepts = [
            "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰",
            "å¤§è¯­è¨€æ¨¡å‹", "GPT", "ChatGPT", "ç”Ÿæˆå¼AI", "å¼ºåŒ–å­¦ä¹ ", "è¿ç§»å­¦ä¹ ", "è”é‚¦å­¦ä¹ ",
            "è¾¹ç¼˜è®¡ç®—", "äº‘è®¡ç®—", "é‡å­è®¡ç®—", "åŒºå—é“¾", "ç‰©è”ç½‘", "5G", "6G"
        ]
        
        self.news_sources = [
            "ç§‘æŠ€æ—¥æŠ¥", "äººæ°‘æ—¥æŠ¥", "æ–°åç¤¾", "å¤®è§†æ–°é—»", "ç¬¬ä¸€è´¢ç»", "36æ°ª", "è™å—…ç½‘",
            "é’›åª’ä½“", "é›·é”‹ç½‘", "æå®¢å…¬å›­", "ITæ¡”å­", "åˆ›ä¸šé‚¦", "æŠ•èµ„ç•Œ", "ç½‘æ˜“ç§‘æŠ€"
        ]
        
        self.news_templates = [
            "{company}å‘å¸ƒæ–°ä¸€ä»£{ai_concept}äº§å“ï¼Œå¼•é¢†è¡Œä¸šåˆ›æ–°",
            "{company}å®£å¸ƒé‡å¤§æŠ€æœ¯çªç ´ï¼Œ{ai_concept}é¢†åŸŸè¿æ¥æ–°æœºé‡",
            "{company}ä¸{company2}è¾¾æˆæˆ˜ç•¥åˆä½œï¼Œå…±åŒæ¨è¿›{ai_concept}å‘å±•",
            "{company}è·å¾—{ai_concept}ç›¸å…³ä¸“åˆ©ï¼ŒæŠ€æœ¯å®åŠ›å†è·è®¤å¯",
            "{company}åœ¨{ai_concept}é¢†åŸŸæŠ•èµ„åŠ ç ï¼Œå¸ƒå±€æœªæ¥ç§‘æŠ€å‘å±•",
            "{company}å‘å¸ƒ{ai_concept}ç ”ç©¶æŠ¥å‘Šï¼Œæ·±åº¦è§£æè¡Œä¸šè¶‹åŠ¿",
            "{company}ä¸¾åŠ{ai_concept}æŠ€æœ¯å³°ä¼šï¼Œæ±‡èšè¡Œä¸šç²¾è‹±",
            "{company}çš„{ai_concept}æŠ€æœ¯è·å¾—å›½é™…è®¤å¯ï¼Œå½°æ˜¾ä¸­å›½ç§‘æŠ€å®åŠ›",
            "{company}æ¨å‡ºåŸºäº{ai_concept}çš„æ–°æœåŠ¡ï¼Œç”¨æˆ·ä½“éªŒå¤§å¹…æå‡",
            "{company}åœ¨{ai_concept}ç«èµ›ä¸­å¤ºå† ï¼ŒæŠ€æœ¯å®åŠ›è·å…¨çƒå…³æ³¨"
        ]
        
        self.news_contents = [
            """è¿‘æ—¥ï¼Œ{company}æ­£å¼å‘å¸ƒäº†å…¶æœ€æ–°çš„{ai_concept}äº§å“ï¼Œè¿™ä¸€åˆ›æ–°æˆæœæ ‡å¿—ç€å…¬å¸åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„æŠ€æœ¯å®åŠ›å†æ¬¡è·å¾—é‡å¤§çªç ´ã€‚
            
            æ®æ‚‰ï¼Œè¯¥äº§å“é‡‡ç”¨äº†æœ€å…ˆè¿›çš„{ai_concept}ç®—æ³•ï¼Œèƒ½å¤Ÿå®ç°{feature1}ã€{feature2}å’Œ{feature3}ç­‰å¤šé¡¹æ ¸å¿ƒåŠŸèƒ½ã€‚å…¬å¸é¦–å¸­æŠ€æœ¯å®˜è¡¨ç¤ºï¼Œè¿™é¡¹æŠ€æœ¯å°†åœ¨æœªæ¥{timeframe}å†…å½»åº•æ”¹å˜ç›¸å…³è¡Œä¸šæ ¼å±€ã€‚
            
            ä¸šå†…ä¸“å®¶è®¤ä¸ºï¼Œ{company}æ­¤æ¬¡å‘å¸ƒçš„æ–°äº§å“ä¸ä»…ä½“ç°äº†å…¶åœ¨{ai_concept}é¢†åŸŸçš„æ·±åšæŠ€æœ¯ç§¯ç´¯ï¼Œæ›´å°†ä¸ºæ•´ä¸ªè¡Œä¸šå¸¦æ¥æ–°çš„å‘å±•æœºé‡ã€‚é¢„è®¡è¯¥äº§å“å°†åœ¨{application_field}é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚
            
            ç›®å‰ï¼Œè¯¥äº§å“å·²ç»å¼€å§‹æ¥å—é¢„è®¢ï¼Œé¢„è®¡å°†åœ¨{launch_time}æ­£å¼æ¨å‘å¸‚åœºã€‚""",
            
            """{company}ä»Šæ—¥å®£å¸ƒï¼Œå…¬å¸åœ¨{ai_concept}æŠ€æœ¯æ–¹é¢å–å¾—é‡å¤§çªç ´æ€§è¿›å±•ï¼Œç›¸å…³ç ”ç©¶æˆæœå·²å‘è¡¨åœ¨å›½é™…é¡¶çº§å­¦æœ¯æœŸåˆŠä¸Šã€‚
            
            æ®å…¬å¸ç ”å‘è´Ÿè´£äººä»‹ç»ï¼Œè¿™é¡¹æ–°æŠ€æœ¯èƒ½å¤Ÿ{technical_advantage}ï¼Œç›¸æ¯”ç°æœ‰æŠ€æœ¯å…·æœ‰{performance_improvement}å€çš„æ€§èƒ½æå‡ã€‚è¯¥æŠ€æœ¯ä¸»è¦åº”ç”¨äº{application_scenario}ç­‰åœºæ™¯ã€‚
            
            {company}è‘£äº‹é•¿å…¼CEOè¡¨ç¤ºï¼š"æˆ‘ä»¬ä¸€ç›´è‡´åŠ›äº{ai_concept}æŠ€æœ¯çš„ç ”å‘å’Œåˆ›æ–°ï¼Œæ­¤æ¬¡çªç ´æ˜¯å…¬å¸å¤šå¹´æ¥æŒç»­æŠ•å…¥çš„ç»“æœã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹æŠ€æœ¯å°†ä¸º{target_industry}è¡Œä¸šå¸¦æ¥é©å‘½æ€§çš„å˜åŒ–ã€‚"
            
            å¸‚åœºåˆ†æå¸ˆæŒ‡å‡ºï¼Œ{company}æ­¤æ¬¡æŠ€æœ¯çªç ´ä¸ä»…å·©å›ºäº†å…¶åœ¨{ai_concept}é¢†åŸŸçš„é¢†å…ˆåœ°ä½ï¼Œæ›´å°†ä¸ºå…¬å¸æœªæ¥å‘å±•æä¾›å¼ºåŠ²åŠ¨åŠ›ã€‚""",
            
            """åœ¨ä»Šæ—¥ä¸¾è¡Œçš„{event_name}å¤§ä¼šä¸Šï¼Œ{company}ä¸{company2}æ­£å¼ç­¾ç½²æˆ˜ç•¥åˆä½œåè®®ï¼ŒåŒæ–¹å°†åœ¨{ai_concept}é¢†åŸŸå±•å¼€æ·±åº¦åˆä½œã€‚
            
            æ ¹æ®åè®®å†…å®¹ï¼Œä¸¤å®¶å…¬å¸å°†å……åˆ†å‘æŒ¥å„è‡ªåœ¨{field1}å’Œ{field2}æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå…±åŒæ¨è¿›{ai_concept}æŠ€æœ¯çš„äº§ä¸šåŒ–åº”ç”¨ã€‚åˆä½œèŒƒå›´æ¶µç›–{cooperation_area1}ã€{cooperation_area2}å’Œ{cooperation_area3}ç­‰å¤šä¸ªæ–¹é¢ã€‚
            
            {company}CEOè¡¨ç¤ºï¼š"æˆ‘ä»¬éå¸¸é«˜å…´èƒ½å¤Ÿä¸{company2}è¾¾æˆæˆ˜ç•¥åˆä½œã€‚åŒæ–¹åœ¨{ai_concept}é¢†åŸŸå…·æœ‰å¾ˆå¼ºçš„äº’è¡¥æ€§ï¼Œè¿™æ¬¡åˆä½œå°†ä¸ºè¡Œä¸šå‘å±•æ³¨å…¥æ–°çš„æ´»åŠ›ã€‚"
            
            {company2}ç›¸å…³è´Ÿè´£äººä¹Ÿè¡¨ç¤ºï¼ŒæœŸå¾…é€šè¿‡åŒæ–¹çš„æ·±åº¦åˆä½œï¼Œå…±åŒæ¨åŠ¨{ai_concept}æŠ€æœ¯çš„åˆ›æ–°ä¸åº”ç”¨ï¼Œä¸ºç”¨æˆ·åˆ›é€ æ›´å¤§ä»·å€¼ã€‚"""
        ]
    
    async def generate_entities(self, count: int = 20):
        """ç”Ÿæˆå®ä½“æ•°æ®"""
        logger.info(f"å¼€å§‹ç”Ÿæˆ {count} ä¸ªå®ä½“...")
        entities = []
        
        # è·å–æ•°æ®åº“ä¼šè¯
        async with self.db_manager.get_session() as session:
            entity_repo = EntityRepository(session)
            
            # ç”Ÿæˆç§‘æŠ€å…¬å¸å®ä½“
            for company in random.sample(self.tech_companies, min(8, len(self.tech_companies))):
                entity = await entity_repo.create({
                    "name": company,
                    "type": "ç§‘æŠ€å…¬å¸",
                    "description": f"{company}æ˜¯ä¸€å®¶ä¸“æ³¨äºäººå·¥æ™ºèƒ½å’Œé«˜ç§‘æŠ€äº§å“ç ”å‘çš„å…¬å¸",
                    "meta_data": {"industry": "ç§‘æŠ€", "focus": "AI", "scale": "large"}
                })
                entities.append(entity)
                logger.info(f"åˆ›å»ºå®ä½“: {company}")
            
            # ç”ŸæˆAIæ¦‚å¿µå®ä½“
            for concept in random.sample(self.ai_concepts, min(8, len(self.ai_concepts))):
                entity = await entity_repo.create({
                    "name": concept,
                    "type": "æŠ€æœ¯æ¦‚å¿µ",
                    "description": f"{concept}æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦æŠ€æœ¯åˆ†æ”¯",
                    "meta_data": {"category": "AI", "maturity": "developing", "applications": ["industry", "research"]}
                })
                entities.append(entity)
                logger.info(f"åˆ›å»ºå®ä½“: {concept}")
            
            # ç”Ÿæˆäººç‰©å®ä½“
            ai_experts = ["æé£é£", "å´æ©è¾¾", "Hinton", "LeCun", "Bengio", "ä½•æºæ˜", "é¢œæ°´æˆ", "å¼ æ½¼"]
            for expert in random.sample(ai_experts, min(4, len(ai_experts))):
                entity = await entity_repo.create(
                    name=expert,
                    type="äººç‰©",
                    description=f"{expert}æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„çŸ¥åä¸“å®¶å’Œå­¦è€…",
                    meta_data={"role": "researcher", "field": "AI", "nationality": "international"}
                )
                entities.append(entity)
                logger.info(f"åˆ›å»ºå®ä½“: {expert}")
        
        logger.info(f"å®ä½“ç”Ÿæˆå®Œæˆï¼Œå…±åˆ›å»º {len(entities)} ä¸ªå®ä½“")
        return entities
    
    async def generate_relations(self, entities: list, count: int = 30):
        """ç”Ÿæˆå…³ç³»æ•°æ®"""
        logger.info(f"å¼€å§‹ç”Ÿæˆ {count} ä¸ªå…³ç³»...")
        relations = []
        
        # è·å–æ•°æ®åº“ä¼šè¯
        async with self.db_manager.get_session() as session:
            relation_repo = RelationRepository(session)
            
            # å®šä¹‰å…³ç³»ç±»å‹
            relation_types = [
                "ç ”å‘", "æŠ•èµ„", "åˆä½œ", "æ”¶è´­", "ç«äº‰", "é¢†å¯¼", "åˆ›æ–°", "åº”ç”¨",
                "æ”¯æŒ", "æ¨åŠ¨", "ä¸“æ³¨äº", "è‡´åŠ›äº", "åœ¨...é¢†åŸŸé¢†å…ˆ", "æ‹¥æœ‰...æŠ€æœ¯"
            ]
            
            for i in range(count):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªå®ä½“
                entity1, entity2 = random.sample(entities, 2)
                predicate = random.choice(relation_types)
                
                # æ ¹æ®å®ä½“ç±»å‹ç”Ÿæˆåˆé€‚çš„æè¿°
                if entity1.type == "ç§‘æŠ€å…¬å¸" and entity2.type == "æŠ€æœ¯æ¦‚å¿µ":
                    description = f"{entity1.name}åœ¨{entity2.name}é¢†åŸŸæœ‰é‡è¦å¸ƒå±€å’ŒæŠ•èµ„"
                elif entity1.type == "äººç‰©" and entity2.type == "æŠ€æœ¯æ¦‚å¿µ":
                    description = f"{entity1.name}æ˜¯{entity2.name}é¢†åŸŸçš„ä¸“å®¶å’Œæ¨åŠ¨è€…"
                elif entity1.type == "ç§‘æŠ€å…¬å¸" and entity2.type == "ç§‘æŠ€å…¬å¸":
                    description = f"{entity1.name}ä¸{entity2.name}åœ¨AIé¢†åŸŸå­˜åœ¨{predicate}å…³ç³»"
                else:
                    description = f"{entity1.name}ä¸{entity2.name}ä¹‹é—´å­˜åœ¨{predicate}å…³ç³»"
                
                relation = await relation_repo.create(
                    subject_id=entity1.id,
                    predicate=predicate,
                    object_id=entity2.id,
                    description=description,
                    meta_data={"confidence": random.uniform(0.7, 1.0), "source": "test_data"}
                )
                relations.append(relation)
                logger.info(f"åˆ›å»ºå…³ç³»: {entity1.name} {predicate} {entity2.name}")
            
            await session.flush()
        
        logger.info(f"å…³ç³»ç”Ÿæˆå®Œæˆï¼Œå…±åˆ›å»º {len(relations)} ä¸ªå…³ç³»")
        return relations
    
    async def generate_news_events(self, entities: list, count: int = 50):
        """ç”Ÿæˆæ–°é—»äº‹ä»¶æ•°æ®"""
        logger.info(f"å¼€å§‹ç”Ÿæˆ {count} æ¡æ–°é—»...")
        news_events = []
        
        # è·å–æ•°æ®åº“ä¼šè¯
        async with self.db_manager.get_session() as session:
            news_repo = NewsEventRepository(session)
            
            for i in range(count):
                # éšæœºé€‰æ‹©å…¬å¸å’ŒAIæ¦‚å¿µ
                company = random.choice([e for e in entities if e.type == "ç§‘æŠ€å…¬å¸"])
                ai_concept = random.choice([e for e in entities if e.type == "æŠ€æœ¯æ¦‚å¿µ"])
                
                # ç”Ÿæˆæ ‡é¢˜
                template = random.choice(self.news_templates)
                if "{company2}" in template:
                    company2 = random.choice([e for e in entities if e.type == "ç§‘æŠ€å…¬å¸" and e.id != company.id])
                    title = template.format(company=company.name, ai_concept=ai_concept.name, company2=company2.name)
                else:
                    title = template.format(company=company.name, ai_concept=ai_concept.name)
                
                # ç”Ÿæˆå†…å®¹
                content_template = random.choice(self.news_contents)
                
                # å¡«å……å†…å®¹æ¨¡æ¿ä¸­çš„å˜é‡
                features = ["æ™ºèƒ½è¯†åˆ«", "è‡ªåŠ¨ä¼˜åŒ–", "ç²¾å‡†é¢„æµ‹", "å®æ—¶åˆ†æ", "æ·±åº¦å­¦ä¹ "]
                application_fields = ["åŒ»ç–—å¥åº·", "é‡‘èæœåŠ¡", "æ•™è‚²åŸ¹è®­", "æ™ºèƒ½åˆ¶é€ ", "è‡ªåŠ¨é©¾é©¶"]
                
                content = content_template.format(
                    company=company.name,
                    ai_concept=ai_concept.name,
                    feature1=random.choice(features),
                    feature2=random.choice(features),
                    feature3=random.choice(features),
                    timeframe="2-3å¹´",
                    application_field=random.choice(application_fields),
                    launch_time="æ˜å¹´ç¬¬ä¸€å­£åº¦",
                    technical_advantage="æ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡",
                    performance_improvement="5-10",
                    application_scenario="å¤§è§„æ¨¡æ•°æ®å¤„ç†",
                    target_industry=random.choice(application_fields),
                    company2=company2.name if "{company2}" in content_template else "",
                    field1="ç®—æ³•ç ”å‘",
                    field2="äº§å“åº”ç”¨",
                    cooperation_area1="æŠ€æœ¯ç ”å‘",
                    cooperation_area2="å¸‚åœºæ¨å¹¿",
                    cooperation_area3="æ ‡å‡†åˆ¶å®š",
                    event_name="å…¨çƒäººå·¥æ™ºèƒ½"
                )
                
                # ç”Ÿæˆå‘å¸ƒæ—¶é—´ï¼ˆæœ€è¿‘ä¸€å¹´å†…éšæœºï¼‰
                publish_time = datetime.now() - timedelta(days=random.randint(1, 365))
                
                # åˆ›å»ºæ–°é—»äº‹ä»¶
                news_event = await news_repo.create(
                    title=title,
                    content=content,
                    source=random.choice(self.news_sources),
                    publish_time=publish_time
                )
                
                # å…³è”ç›¸å…³å®ä½“
                await news_repo.add_entity_relation(news_event.id, company.id)
                await news_repo.add_entity_relation(news_event.id, ai_concept.id)
                
                # éšæœºæ·»åŠ æ›´å¤šç›¸å…³å®ä½“
                if random.random() > 0.5 and len(entities) > 2:
                    extra_entity = random.choice([e for e in entities if e.id not in [company.id, ai_concept.id]])
                    await news_repo.add_entity_relation(news_event.id, extra_entity.id)
                
                news_events.append(news_event)
                logger.info(f"åˆ›å»ºæ–°é—»: {title[:50]}...")
            
            await session.flush()
        
        logger.info(f"æ–°é—»ç”Ÿæˆå®Œæˆï¼Œå…±åˆ›å»º {len(news_events)} æ¡æ–°é—»")
        return news_events
    
    async def generate_vector_embeddings(self, news_events: list):
        """ä¸ºæ–°é—»ç”Ÿæˆå‘é‡åµŒå…¥"""
        logger.info(f"å¼€å§‹ä¸º {len(news_events)} æ¡æ–°é—»ç”Ÿæˆå‘é‡åµŒå…¥...")
        
        try:
            # æ‰¹é‡ç”ŸæˆåµŒå…¥
            texts = [f"{news.title} {news.content[:200]}" for news in news_events]
            embeddings = await self.embedding_service.generate_embeddings(texts)
            
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            for i, news in enumerate(news_events):
                vector_id = await self.hybrid_store.add_news_event(
                    news_id=news.id,
                    title=news.title,
                    content=news.content,
                    embedding=embeddings[i],
                    metadata={
                        "source": news.source,
                        "publish_time": news.publish_time.isoformat() if news.publish_time else None,
                        "entities": [e.name for e in news.entities] if hasattr(news, 'entities') else []
                    }
                )
                
                # æ›´æ–°æ–°é—»çš„å‘é‡ID
                news.vector_id = vector_id
                logger.info(f"ç”Ÿæˆå‘é‡åµŒå…¥: {news.title[:30]}...")
            
            await self.session.flush()
            logger.info("å‘é‡åµŒå…¥ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå‘é‡åµŒå…¥å¤±è´¥: {e}")
            # ä¸ä¸­æ–­æµ‹è¯•ï¼Œç»§ç»­æ‰§è¡Œ
    
    async def generate_all_test_data(self):
        """ç”Ÿæˆæ‰€æœ‰æµ‹è¯•æ•°æ®"""
        logger.info("å¼€å§‹ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æ•°æ®...")
        
        try:
            # ç”Ÿæˆå®ä½“
            entities = await self.generate_entities(20)
            
            # ç”Ÿæˆå…³ç³»
            relations = await self.generate_relations(entities)
            
            # ç”Ÿæˆæ–°é—»äº‹ä»¶
            news_events = await self.generate_news_events(entities, 50)
            
            # ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆæš‚æ—¶æ³¨é‡Šæ‰ï¼‰
            # await self.generate_vector_embeddings(news_events)
            
            logger.info("æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼")
            logger.info(f"å®ä½“æ•°é‡: {len(entities)}")
            logger.info(f"å…³ç³»æ•°é‡: {len(relations)}")
            logger.info(f"æ–°é—»æ•°é‡: {len(news_events)}")
            
            return {
                "entities": entities,
                "relations": relations,
                "news_events": news_events
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•æ•°æ®æ—¶å‡ºé”™: {e}")
            raise


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    
    # åˆå§‹åŒ–æ•°æ®åº“é…ç½®
    from app.database.core import DatabaseConfig
    from app.database.manager import init_database
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    config = DatabaseConfig()
    db_manager = init_database(config)
    
    # åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨
    generator = TestDataGenerator(db_manager)
    
    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        result = await generator.generate_all_test_data()
        
        logger.info("âœ… æµ‹è¯•æ•°æ®ç”ŸæˆæˆåŠŸ")
        logger.info(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: {result}")
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return 1
    finally:
        # æ¸…ç†èµ„æº
        if 'db_manager' in locals():
            await db_manager.close()


if __name__ == "__main__":
    asyncio.run(main())